# Python zipfile æ¨™æº–åº«æœ€ä½³å¯¦è¸ç ”ç©¶å ±å‘Š

**ç ”ç©¶æ—¥æœŸ**: 2025-10-25  
**ç›®æ¨™åŠŸèƒ½**: è³‡æ–™åŒ¯å‡º/åŒ¯å…¥åŠŸèƒ½  
**ç ”ç©¶ç¯„åœ**: Python zipfile æ¨™æº–åº«çš„å®‰å…¨ä½¿ç”¨ã€æª”æ¡ˆé©—è­‰ã€éŒ¯èª¤è™•ç†

---

## åŸ·è¡Œæ‘˜è¦

æœ¬ç ”ç©¶é‡å° `work-plan-by-calendar` å°ˆæ¡ˆçš„è³‡æ–™åŒ¯å‡º/åŒ¯å…¥åŠŸèƒ½,æ·±å…¥æ¢è¨ Python `zipfile` æ¨™æº–åº«çš„æœ€ä½³å¯¦è¸ã€‚ä¸»è¦ç™¼ç¾åŒ…æ‹¬:

1. **å®‰å…¨æ€§**: å¿…é ˆå¯¦ä½œ Zip Slip é˜²è­·,ä½¿ç”¨ `os.path.realpath()` å’Œè·¯å¾‘é©—è­‰
2. **è¨˜æ†¶é«”æ•ˆç‡**: ä½¿ç”¨ `zipfile.ZipFile` çš„è¿­ä»£å¼è™•ç†,é¿å…ä¸€æ¬¡æ€§è¼‰å…¥æ‰€æœ‰å…§å®¹
3. **æª”æ¡ˆé©—è­‰**: å¯¦ä½œå¤šå±¤é©—è­‰æ©Ÿåˆ¶(çµæ§‹ã€å‘½åã€æ—¥æœŸã€å¤§å°)
4. **åŸå­æ€§æ“ä½œ**: ä½¿ç”¨è‡¨æ™‚ç›®éŒ„ + é©—è­‰ + åŸå­æ€§ç§»å‹•ç¢ºä¿è³‡æ–™ä¸€è‡´æ€§

---

## 1. å®‰å…¨çš„ ZIP å»ºç«‹

### 1.1 æ±ºç­–: éè¿´å£“ç¸®ç›®éŒ„çµæ§‹

**æ¨è–¦åšæ³•**: ä½¿ç”¨ `os.walk()` éæ­·ç›®éŒ„æ¨¹,é…åˆ `zipfile.write()` é€ä¸€æ·»åŠ æª”æ¡ˆ

```python
import os
import zipfile
from pathlib import Path
from datetime import datetime
from typing import Optional

def create_data_export(data_dir: str, output_path: Optional[str] = None) -> str:
    """
    å®‰å…¨åœ°å°‡æ•´å€‹ data ç›®éŒ„å£“ç¸®ç‚º ZIP æª”æ¡ˆ
    
    Args:
        data_dir: è¦å£“ç¸®çš„è³‡æ–™ç›®éŒ„è·¯å¾‘ (ä¾‹å¦‚ 'backend/data')
        output_path: è¼¸å‡º ZIP æª”æ¡ˆè·¯å¾‘,è‹¥ç‚º None å‰‡è‡ªå‹•ç”Ÿæˆ
        
    Returns:
        ç”Ÿæˆçš„ ZIP æª”æ¡ˆè·¯å¾‘
        
    Raises:
        FileNotFoundError: ç•¶ data_dir ä¸å­˜åœ¨
        PermissionError: ç•¶æ²’æœ‰è®€å–æ¬Šé™
        OSError: ç•¶ç£ç¢Ÿç©ºé–“ä¸è¶³æˆ–å…¶ä»– I/O éŒ¯èª¤
    """
    data_path = Path(data_dir)
    
    # é©—è­‰ä¾†æºç›®éŒ„å­˜åœ¨
    if not data_path.exists():
        raise FileNotFoundError(f"Data directory not found: {data_dir}")
    
    if not data_path.is_dir():
        raise NotADirectoryError(f"Path is not a directory: {data_dir}")
    
    # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆåç¨±
    if output_path is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"export_data_{timestamp}.zip"
    
    output_file = Path(output_path)
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    # å»ºç«‹ ZIP æª”æ¡ˆ (ä½¿ç”¨ deflate å£“ç¸®)
    # ZIP_DEFLATED æä¾›è‰¯å¥½çš„å£“ç¸®ç‡,é©åˆæ–‡å­—æª”æ¡ˆ
    with zipfile.ZipFile(output_file, 'w', zipfile.ZIP_DEFLATED) as zipf:
        # éè¿´éæ­·ç›®éŒ„
        for root, dirs, files in os.walk(data_path):
            # éæ¿¾éš±è—æª”æ¡ˆå’Œç³»çµ±æª”æ¡ˆ
            files = [f for f in files if not f.startswith('.') and f.endswith('.md')]
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            
            for file in files:
                file_path = Path(root) / file
                
                # è¨ˆç®— ZIP å…§çš„ç›¸å°è·¯å¾‘
                # ä¾‹å¦‚: backend/data/Day/20250101.md -> Day/20250101.md
                arcname = file_path.relative_to(data_path.parent)
                
                # æ·»åŠ æª”æ¡ˆåˆ° ZIP
                zipf.write(file_path, arcname=arcname)
    
    return str(output_file)
```

**ç†ç”±**:
- `os.walk()` æ˜¯æ¨™æº–åº«ä¸­æœ€å¯é çš„ç›®éŒ„éæ­·æ–¹æ³•
- `relative_to()` ç¢ºä¿ ZIP å…§è·¯å¾‘æ­£ç¢º,ä¿æŒç›®éŒ„çµæ§‹
- éæ¿¾éš±è—æª”æ¡ˆé¿å…åŒ…å« `.DS_Store` ç­‰ç³»çµ±æª”æ¡ˆ
- `ZIP_DEFLATED` å° markdown æ–‡å­—æª”æä¾› 60-80% å£“ç¸®ç‡

**æ›¿ä»£æ–¹æ¡ˆ**:
- âŒ `shutil.make_archive()`: ç„¡æ³•ç´°ç·»æ§åˆ¶æª”æ¡ˆéæ¿¾å’Œè·¯å¾‘çµæ§‹
- âŒ æ‰‹å‹•éè¿´: ç¨‹å¼ç¢¼è¤‡é›œä¸”å®¹æ˜“å‡ºéŒ¯
- âœ… `pathlib.Path.rglob()`: å¯ç”¨,ä½† `os.walk()` æä¾›æ›´å¤šæ§åˆ¶

---

### 1.2 æ±ºç­–: è¨˜æ†¶é«”æ•ˆç‡è€ƒé‡

**æ¨è–¦åšæ³•**: ä½¿ç”¨é è¨­çš„ `zipfile.write()` ä¸²æµæ¨¡å¼,é¿å…è¼‰å…¥æª”æ¡ˆå…§å®¹åˆ°è¨˜æ†¶é«”

```python
def create_data_export_efficient(data_dir: str, output_path: str, 
                                   max_file_size: int = 10 * 1024 * 1024) -> dict:
    """
    è¨˜æ†¶é«”æ•ˆç‡å„ªåŒ–çš„åŒ¯å‡ºåŠŸèƒ½
    
    Args:
        data_dir: è³‡æ–™ç›®éŒ„
        output_path: è¼¸å‡ºè·¯å¾‘
        max_file_size: å–®ä¸€æª”æ¡ˆå¤§å°ä¸Šé™ (é è¨­ 10MB)
        
    Returns:
        åŒ…å«çµ±è¨ˆè³‡è¨Šçš„å­—å…¸: {
            'total_files': int,
            'total_size': int,
            'compressed_size': int,
            'skipped_files': list
        }
    """
    stats = {
        'total_files': 0,
        'total_size': 0,
        'compressed_size': 0,
        'skipped_files': []
    }
    
    data_path = Path(data_dir)
    
    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED, 
                         compresslevel=6) as zipf:  # å£“ç¸®ç­‰ç´š 6 = é€Ÿåº¦èˆ‡å£“ç¸®ç‡å¹³è¡¡
        
        for root, dirs, files in os.walk(data_path):
            files = [f for f in files if not f.startswith('.') and f.endswith('.md')]
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            
            for file in files:
                file_path = Path(root) / file
                file_size = file_path.stat().st_size
                
                # æª¢æŸ¥æª”æ¡ˆå¤§å°é™åˆ¶
                if file_size > max_file_size:
                    stats['skipped_files'].append({
                        'path': str(file_path),
                        'reason': f'File too large: {file_size} bytes',
                        'size': file_size
                    })
                    continue
                
                arcname = file_path.relative_to(data_path.parent)
                
                # zipfile.write() å…§éƒ¨ä½¿ç”¨ä¸²æµ,ä¸æœƒä¸€æ¬¡è¼‰å…¥æ•´å€‹æª”æ¡ˆ
                zipf.write(file_path, arcname=arcname)
                
                stats['total_files'] += 1
                stats['total_size'] += file_size
        
        # å–å¾—å£“ç¸®å¾Œå¤§å°
        stats['compressed_size'] = Path(output_path).stat().st_size
    
    return stats
```

**ç†ç”±**:
- `zipfile.write()` é è¨­ä½¿ç”¨ 8KB ç·©è¡å€,è‡ªå‹•è™•ç†å¤§æª”æ¡ˆ
- `compresslevel=6` æä¾›é€Ÿåº¦èˆ‡å£“ç¸®ç‡çš„å¹³è¡¡(ç¯„åœ 0-9)
- è¨˜éŒ„çµ±è¨ˆè³‡è¨Šæœ‰åŠ©æ–¼ç›£æ§å’Œé™¤éŒ¯
- æª”æ¡ˆå¤§å°é™åˆ¶é˜²æ­¢ç•°å¸¸å¤§æª”æ¡ˆ

**æ•ˆèƒ½æ•¸æ“š** (åƒè€ƒå€¼):
- 1000 å€‹ markdown æª”æ¡ˆ (å¹³å‡ 5KB/æª”): ~2-3 ç§’
- è¨˜æ†¶é«”ä½¿ç”¨: ~10-20MB (å›ºå®š,ä¸éš¨æª”æ¡ˆæ•¸é‡å¢é•·)
- å£“ç¸®ç‡: ~70% (markdown æ–‡å­—æª”)

---

## 2. å®‰å…¨çš„ ZIP è§£å£“ç¸®

### 2.1 æ±ºç­–: é˜²æ­¢ Zip Slip æ¼æ´

**Zip Slip æ¼æ´èªªæ˜**: æƒ¡æ„ ZIP æª”æ¡ˆå¯èƒ½åŒ…å« `../../../etc/passwd` ç­‰è·¯å¾‘,è§£å£“æ™‚æœƒè¦†å¯«ç³»çµ±æª”æ¡ˆ

**æ¨è–¦åšæ³•**: é©—è­‰æ‰€æœ‰è§£å£“ç¸®è·¯å¾‘éƒ½åœ¨é æœŸç›®éŒ„å…§

```python
import os
from pathlib import Path
from typing import List, Tuple

def safe_extract_member(zipf: zipfile.ZipFile, member: zipfile.ZipInfo, 
                        target_dir: Path) -> Path:
    """
    å®‰å…¨åœ°è§£å£“ç¸®å–®ä¸€ ZIP æˆå“¡,é˜²æ­¢è·¯å¾‘ç©¿è¶Šæ”»æ“Š
    
    Args:
        zipf: ZipFile ç‰©ä»¶
        member: è¦è§£å£“ç¸®çš„æˆå“¡
        target_dir: ç›®æ¨™ç›®éŒ„
        
    Returns:
        è§£å£“ç¸®å¾Œçš„æª”æ¡ˆè·¯å¾‘
        
    Raises:
        ValueError: ç•¶åµæ¸¬åˆ°è·¯å¾‘ç©¿è¶Šæ”»æ“Š
    """
    # å–å¾—çµ•å°è·¯å¾‘
    target_dir = target_dir.resolve()
    
    # è¨ˆç®—è§£å£“ç¸®å¾Œçš„å®Œæ•´è·¯å¾‘
    member_path = (target_dir / member.filename).resolve()
    
    # æª¢æŸ¥æ˜¯å¦åœ¨ç›®æ¨™ç›®éŒ„å…§
    # ä½¿ç”¨ resolve() è§£æç¬¦è™Ÿé€£çµå’Œ '..' è·¯å¾‘
    if not str(member_path).startswith(str(target_dir)):
        raise ValueError(
            f"Attempted Path Traversal in Zip File: {member.filename}"
        )
    
    # å®‰å…¨è§£å£“ç¸®
    zipf.extract(member, target_dir)
    
    return member_path


def safe_extract_all(zip_path: str, target_dir: str) -> List[Path]:
    """
    å®‰å…¨åœ°è§£å£“ç¸®æ•´å€‹ ZIP æª”æ¡ˆ
    
    Args:
        zip_path: ZIP æª”æ¡ˆè·¯å¾‘
        target_dir: ç›®æ¨™ç›®éŒ„
        
    Returns:
        æ‰€æœ‰è§£å£“ç¸®çš„æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        
    Raises:
        ValueError: ç•¶åµæ¸¬åˆ°å®‰å…¨å•é¡Œ
        zipfile.BadZipFile: ç•¶ ZIP æª”æ¡ˆæå£
    """
    target_path = Path(target_dir)
    target_path.mkdir(parents=True, exist_ok=True)
    
    extracted_files = []
    
    with zipfile.ZipFile(zip_path, 'r') as zipf:
        # å…ˆæª¢æŸ¥æ‰€æœ‰æˆå“¡
        for member in zipf.namelist():
            # é˜²æ­¢çµ•å°è·¯å¾‘
            if member.startswith('/') or member.startswith('\\'):
                raise ValueError(f"Absolute path not allowed: {member}")
            
            # é˜²æ­¢ Windows ç£ç¢Ÿè·¯å¾‘
            if ':' in member:
                raise ValueError(f"Drive letter not allowed: {member}")
        
        # å®‰å…¨è§£å£“ç¸®
        for member_info in zipf.infolist():
            # è·³éç›®éŒ„
            if member_info.is_dir():
                continue
            
            file_path = safe_extract_member(zipf, member_info, target_path)
            extracted_files.append(file_path)
    
    return extracted_files
```

**ç†ç”±**:
- `Path.resolve()` æœƒè§£ææ‰€æœ‰ç¬¦è™Ÿé€£çµå’Œ `..` è·¯å¾‘
- å­—ä¸²å‰ç¶´æª¢æŸ¥ç¢ºä¿è·¯å¾‘åœ¨ç›®æ¨™ç›®éŒ„å…§
- æ˜ç¢ºæ‹’çµ•çµ•å°è·¯å¾‘å’Œç£ç¢Ÿä»£è™Ÿ
- Python 3.12+ å¯ä½¿ç”¨ `zipfile.Path` é€²ä¸€æ­¥ç°¡åŒ–

**å·²çŸ¥æ¼æ´æ¡ˆä¾‹**:
```python
# æƒ¡æ„ ZIP ç¯„ä¾‹
# æˆå“¡åç¨±: "../../../etc/passwd"
# å¦‚æœä¸é©—è­‰,æœƒè¦†å¯«ç³»çµ±æª”æ¡ˆ
```

---

### 2.2 æ±ºç­–: ZIP æª”æ¡ˆçµæ§‹é©—è­‰

**æ¨è–¦åšæ³•**: åœ¨è§£å£“ç¸®å‰é©—è­‰ç›®éŒ„çµæ§‹å’Œæª”æ¡ˆå‘½å

```python
import re
from datetime import datetime
from typing import Dict, List, Optional

class ValidationError(Exception):
    """é©—è­‰éŒ¯èª¤çš„è‡ªå®šç¾©ä¾‹å¤–"""
    pass


class ZipValidator:
    """ZIP æª”æ¡ˆé©—è­‰å™¨"""
    
    # é æœŸçš„ç›®éŒ„çµæ§‹
    REQUIRED_DIRS = {'data/Day', 'data/Week', 'data/Month', 'data/Year'}
    
    # æª”åæ¨¡å¼
    PATTERNS = {
        'Day': re.compile(r'^data/Day/(\d{8})\.md$'),      # YYYYMMDD.md
        'Week': re.compile(r'^data/Week/(\d{8})\.md$'),    # YYYYMMDD.md (å¿…é ˆæ˜¯å‘¨æ—¥)
        'Month': re.compile(r'^data/Month/(\d{6})\.md$'),  # YYYYMM.md
        'Year': re.compile(r'^data/Year/(\d{4})\.md$'),    # YYYY.md
    }
    
    def __init__(self, max_files: int = 10000, max_total_size: int = 100 * 1024 * 1024):
        """
        Args:
            max_files: æª”æ¡ˆæ•¸é‡ä¸Šé™
            max_total_size: ç¸½å¤§å°ä¸Šé™ (é è¨­ 100MB)
        """
        self.max_files = max_files
        self.max_total_size = max_total_size
        self.errors: List[str] = []
        self.warnings: List[str] = []
    
    def validate(self, zip_path: str) -> Tuple[bool, Dict]:
        """
        é©—è­‰ ZIP æª”æ¡ˆ
        
        Returns:
            (æ˜¯å¦é€šé, é©—è­‰å ±å‘Š)
        """
        self.errors = []
        self.warnings = []
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                # 1. æª¢æŸ¥æª”æ¡ˆå®Œæ•´æ€§
                bad_file = zipf.testzip()
                if bad_file:
                    self.errors.append(f"Corrupted file in ZIP: {bad_file}")
                    return False, self._generate_report()
                
                # 2. æª¢æŸ¥å¤§å°é™åˆ¶
                total_size = sum(info.file_size for info in zipf.infolist())
                if total_size > self.max_total_size:
                    self.errors.append(
                        f"ZIP too large: {total_size} bytes (max: {self.max_total_size})"
                    )
                    return False, self._generate_report()
                
                # 3. æª¢æŸ¥æª”æ¡ˆæ•¸é‡
                file_count = len([m for m in zipf.namelist() if not m.endswith('/')])
                if file_count > self.max_files:
                    self.errors.append(
                        f"Too many files: {file_count} (max: {self.max_files})"
                    )
                    return False, self._generate_report()
                
                # 4. æª¢æŸ¥ç›®éŒ„çµæ§‹
                self._validate_structure(zipf)
                
                # 5. æª¢æŸ¥æª”åå’Œå…§å®¹
                self._validate_files(zipf)
        
        except zipfile.BadZipFile:
            self.errors.append("Not a valid ZIP file")
            return False, self._generate_report()
        except Exception as e:
            self.errors.append(f"Validation error: {str(e)}")
            return False, self._generate_report()
        
        # æœ‰éŒ¯èª¤å°±ä¸é€šé
        passed = len(self.errors) == 0
        return passed, self._generate_report()
    
    def _validate_structure(self, zipf: zipfile.ZipFile) -> None:
        """é©—è­‰ç›®éŒ„çµæ§‹"""
        members = set(zipf.namelist())
        
        # æª¢æŸ¥å¿…è¦ç›®éŒ„
        for required_dir in self.REQUIRED_DIRS:
            # ç›®éŒ„å¯èƒ½ä»¥ / çµå°¾æˆ–ä¸çµå°¾
            dir_exists = (
                required_dir in members or 
                f"{required_dir}/" in members or
                any(m.startswith(f"{required_dir}/") for m in members)
            )
            
            if not dir_exists:
                self.errors.append(f"Missing required directory: {required_dir}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰éé æœŸçš„é ‚å±¤ç›®éŒ„
        top_level_dirs = set()
        for member in members:
            if '/' in member:
                top_dir = member.split('/')[0]
                top_level_dirs.add(top_dir)
        
        if top_level_dirs != {'data'}:
            unexpected = top_level_dirs - {'data'}
            if unexpected:
                self.warnings.append(
                    f"Unexpected top-level directories: {', '.join(unexpected)}"
                )
    
    def _validate_files(self, zipf: zipfile.ZipFile) -> None:
        """é©—è­‰æª”æ¡ˆå‘½åå’Œå…§å®¹"""
        for member in zipf.namelist():
            # è·³éç›®éŒ„
            if member.endswith('/'):
                continue
            
            # è·³éé .md æª”æ¡ˆ
            if not member.endswith('.md'):
                self.warnings.append(f"Non-markdown file: {member}")
                continue
            
            # æª¢æŸ¥æª”åæ ¼å¼
            plan_type = None
            date_str = None
            
            for ptype, pattern in self.PATTERNS.items():
                match = pattern.match(member)
                if match:
                    plan_type = ptype
                    date_str = match.group(1)
                    break
            
            if not plan_type:
                self.errors.append(f"Invalid filename format: {member}")
                continue
            
            # é©—è­‰æ—¥æœŸæœ‰æ•ˆæ€§
            self._validate_date(plan_type, date_str, member)
    
    def _validate_date(self, plan_type: str, date_str: str, filename: str) -> None:
        """é©—è­‰æ—¥æœŸæœ‰æ•ˆæ€§"""
        try:
            if plan_type == 'Day' or plan_type == 'Week':
                # YYYYMMDD
                year = int(date_str[:4])
                month = int(date_str[4:6])
                day = int(date_str[6:8])
                date_obj = datetime(year, month, day).date()
                
                # å‘¨è¨ˆç•«å¿…é ˆæ˜¯å‘¨æ—¥
                if plan_type == 'Week':
                    # Python: Monday=0, Sunday=6
                    if date_obj.weekday() != 6:
                        self.errors.append(
                            f"Week plan date is not Sunday: {filename} "
                            f"({date_obj.strftime('%A')})"
                        )
            
            elif plan_type == 'Month':
                # YYYYMM
                year = int(date_str[:4])
                month = int(date_str[4:6])
                if month < 1 or month > 12:
                    raise ValueError("Invalid month")
            
            elif plan_type == 'Year':
                # YYYY
                year = int(date_str)
                if year < 1900 or year > 2100:
                    self.warnings.append(
                        f"Unusual year: {filename} (year={year})"
                    )
        
        except ValueError as e:
            self.errors.append(f"Invalid date in filename {filename}: {str(e)}")
    
    def _generate_report(self) -> Dict:
        """ç”Ÿæˆé©—è­‰å ±å‘Š"""
        return {
            'passed': len(self.errors) == 0,
            'errors': self.errors.copy(),
            'warnings': self.warnings.copy(),
            'error_count': len(self.errors),
            'warning_count': len(self.warnings)
        }


# ä½¿ç”¨ç¯„ä¾‹
def validate_import_file(zip_path: str) -> Dict:
    """é©—è­‰åŒ¯å…¥æª”æ¡ˆ"""
    validator = ZipValidator(
        max_files=10000,
        max_total_size=100 * 1024 * 1024  # 100MB
    )
    
    passed, report = validator.validate(zip_path)
    
    return report
```

**ç†ç”±**:
- å¤šå±¤é©—è­‰ç¢ºä¿è³‡æ–™å®Œæ•´æ€§å’Œå®‰å…¨æ€§
- æå‰ç™¼ç¾å•é¡Œ,é¿å…éƒ¨åˆ†åŒ¯å…¥
- è©³ç´°çš„éŒ¯èª¤å ±å‘Šå¹«åŠ©ä½¿ç”¨è€…ä¿®æ­£å•é¡Œ
- å€åˆ†éŒ¯èª¤å’Œè­¦å‘Š,æä¾›å½ˆæ€§

**é©—è­‰å±¤ç´š**:
1. **çµæ§‹å±¤**: æª”æ¡ˆå®Œæ•´æ€§ã€å¤§å°ã€æ•¸é‡
2. **ç›®éŒ„å±¤**: å¿…è¦ç›®éŒ„å­˜åœ¨æ€§
3. **æª”åå±¤**: å‘½åæ ¼å¼æ­£ç¢ºæ€§
4. **èªç¾©å±¤**: æ—¥æœŸæœ‰æ•ˆæ€§ã€æ˜ŸæœŸé©—è­‰

---

## 3. FastAPI æ•´åˆèˆ‡åŸå­æ€§æ“ä½œ

### 3.1 æ±ºç­–: ä½¿ç”¨è‡¨æ™‚ç›®éŒ„å¯¦ç¾åŸå­æ€§

**æ¨è–¦åšæ³•**: å…ˆè§£å£“åˆ°è‡¨æ™‚ç›®éŒ„,é©—è­‰é€šéå¾Œå†åŸå­æ€§ç§»å‹•

```python
import tempfile
import shutil
from pathlib import Path
from fastapi import UploadFile, HTTPException
from typing import Dict

class DataImporter:
    """è³‡æ–™åŒ¯å…¥æœå‹™"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.validator = ZipValidator()
    
    async def import_data(self, upload_file: UploadFile) -> Dict:
        """
        åŒ¯å…¥è³‡æ–™ (åŸå­æ€§æ“ä½œ)
        
        Args:
            upload_file: ä¸Šå‚³çš„ ZIP æª”æ¡ˆ
            
        Returns:
            åŒ¯å…¥çµæœå ±å‘Š
            
        Raises:
            HTTPException: ç•¶é©—è­‰æˆ–åŒ¯å…¥å¤±æ•—
        """
        # å»ºç«‹è‡¨æ™‚ç›®éŒ„
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            zip_path = temp_path / "upload.zip"
            extract_path = temp_path / "extracted"
            
            try:
                # 1. å„²å­˜ä¸Šå‚³çš„æª”æ¡ˆ
                await self._save_upload(upload_file, zip_path)
                
                # 2. é©—è­‰ ZIP æª”æ¡ˆ
                validation_report = self.validator.validate(str(zip_path))
                
                if not validation_report['passed']:
                    raise HTTPException(
                        status_code=400,
                        detail={
                            'error': 'Validation failed',
                            'report': validation_report
                        }
                    )
                
                # 3. è§£å£“ç¸®åˆ°è‡¨æ™‚ç›®éŒ„
                extract_path.mkdir(parents=True, exist_ok=True)
                extracted_files = safe_extract_all(str(zip_path), str(extract_path))
                
                # 4. åŸå­æ€§ç§»å‹•æª”æ¡ˆ
                self._atomic_move(extract_path / "data", self.data_dir)
                
                return {
                    'success': True,
                    'files_imported': len(extracted_files),
                    'warnings': validation_report.get('warnings', [])
                }
            
            except HTTPException:
                raise
            except Exception as e:
                raise HTTPException(
                    status_code=500,
                    detail={
                        'error': 'Import failed',
                        'message': str(e)
                    }
                )
            # finally å€å¡Šä¸éœ€è¦,å› ç‚º tempfile.TemporaryDirectory æœƒè‡ªå‹•æ¸…ç†
    
    async def _save_upload(self, upload_file: UploadFile, dest: Path) -> None:
        """å„²å­˜ä¸Šå‚³æª”æ¡ˆ (ä¸²æµæ¨¡å¼)"""
        # ä½¿ç”¨ä¸²æµé¿å…è¨˜æ†¶é«”çˆ†ç‚¸
        with dest.open('wb') as f:
            while chunk := await upload_file.read(8192):  # 8KB chunks
                f.write(chunk)
    
    def _atomic_move(self, src_dir: Path, dest_dir: Path) -> None:
        """
        åŸå­æ€§ç§»å‹•ç›®éŒ„å…§å®¹
        
        ç­–ç•¥: 
        1. å‚™ä»½ç¾æœ‰è³‡æ–™
        2. ç§»å‹•æ–°è³‡æ–™
        3. æˆåŠŸå¾Œåˆªé™¤å‚™ä»½,å¤±æ•—å‰‡é‚„åŸ
        """
        backup_dir = dest_dir.parent / f"{dest_dir.name}_backup_{int(datetime.now().timestamp())}"
        
        try:
            # å‚™ä»½ç¾æœ‰è³‡æ–™ (å¦‚æœå­˜åœ¨)
            if dest_dir.exists():
                shutil.move(str(dest_dir), str(backup_dir))
            
            # ç§»å‹•æ–°è³‡æ–™
            shutil.move(str(src_dir), str(dest_dir))
            
            # æˆåŠŸå¾Œåˆªé™¤å‚™ä»½
            if backup_dir.exists():
                shutil.rmtree(backup_dir)
        
        except Exception as e:
            # é‚„åŸå‚™ä»½
            if backup_dir.exists():
                if dest_dir.exists():
                    shutil.rmtree(dest_dir)
                shutil.move(str(backup_dir), str(dest_dir))
            
            raise RuntimeError(f"Atomic move failed: {str(e)}")
```

**ç†ç”±**:
- `tempfile.TemporaryDirectory` è‡ªå‹•æ¸…ç†,é¿å…éºç•™æª”æ¡ˆ
- å‚™ä»½æ©Ÿåˆ¶ç¢ºä¿å¤±æ•—æ™‚å¯å›æ»¾
- `shutil.move()` åœ¨åŒä¸€æª”æ¡ˆç³»çµ±ä¸Šæ˜¯åŸå­æ€§çš„
- ä¸²æµä¸Šå‚³é¿å…è¨˜æ†¶é«”å•é¡Œ

**åŸå­æ€§ä¿è­‰**:
- âœ… åŒä¸€æª”æ¡ˆç³»çµ±: `shutil.move()` æ˜¯åŸå­æ€§é‡å‘½å
- âš ï¸ è·¨æª”æ¡ˆç³»çµ±: æœƒé€€åŒ–ç‚ºè¤‡è£½+åˆªé™¤,éåŸå­æ€§
- ğŸ”§ è§£æ±ºæ–¹æ¡ˆ: ç¢ºä¿è‡¨æ™‚ç›®éŒ„èˆ‡è³‡æ–™ç›®éŒ„åœ¨åŒä¸€æª”æ¡ˆç³»çµ±

---

### 3.2 æ±ºç­–: FastAPI ç«¯é»è¨­è¨ˆ

```python
from fastapi import APIRouter, UploadFile, File, HTTPException
from fastapi.responses import FileResponse
import logging

router = APIRouter(prefix="/api/data", tags=["data"])
logger = logging.getLogger(__name__)

# å…¨åŸŸåŒ¯å…¥å™¨å¯¦ä¾‹
importer = DataImporter(data_dir="backend/data")


@router.post("/export")
async def export_data():
    """
    åŒ¯å‡ºæ‰€æœ‰å·¥ä½œè¨ˆç•«è³‡æ–™
    
    Returns:
        ZIP æª”æ¡ˆä¸‹è¼‰
    """
    try:
        # å»ºç«‹åŒ¯å‡ºæª”æ¡ˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        zip_filename = f"export_data_{timestamp}.zip"
        zip_path = Path(tempfile.gettempdir()) / zip_filename
        
        stats = create_data_export_efficient(
            data_dir="backend/data",
            output_path=str(zip_path)
        )
        
        logger.info(f"Data exported: {stats}")
        
        # å›å‚³æª”æ¡ˆ
        return FileResponse(
            path=str(zip_path),
            filename=zip_filename,
            media_type="application/zip",
            headers={
                "Content-Disposition": f'attachment; filename="{zip_filename}"'
            }
        )
    
    except Exception as e:
        logger.error(f"Export failed: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"error": "Export failed", "message": str(e)}
        )


@router.post("/validate")
async def validate_import(file: UploadFile = File(...)):
    """
    é©—è­‰åŒ¯å…¥æª”æ¡ˆ (ä¸åŸ·è¡ŒåŒ¯å…¥)
    
    Args:
        file: ä¸Šå‚³çš„ ZIP æª”æ¡ˆ
        
    Returns:
        é©—è­‰å ±å‘Š
    """
    if not file.filename.endswith('.zip'):
        raise HTTPException(
            status_code=400,
            detail={"error": "Invalid file type", "message": "Only .zip files are allowed"}
        )
    
    with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_file:
        try:
            # å„²å­˜ä¸Šå‚³æª”æ¡ˆ
            content = await file.read()
            temp_file.write(content)
            temp_file.flush()
            
            # é©—è­‰
            validator = ZipValidator()
            passed, report = validator.validate(temp_file.name)
            
            return {
                "filename": file.filename,
                "validation": report
            }
        
        finally:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            Path(temp_file.name).unlink(missing_ok=True)


@router.post("/import")
async def import_data(file: UploadFile = File(...)):
    """
    åŒ¯å…¥å·¥ä½œè¨ˆç•«è³‡æ–™
    
    Args:
        file: ä¸Šå‚³çš„ ZIP æª”æ¡ˆ
        
    Returns:
        åŒ¯å…¥çµæœ
    """
    if not file.filename.endswith('.zip'):
        raise HTTPException(
            status_code=400,
            detail={"error": "Invalid file type", "message": "Only .zip files are allowed"}
        )
    
    try:
        result = await importer.import_data(file)
        logger.info(f"Data imported successfully: {result}")
        return result
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Import failed: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"error": "Import failed", "message": str(e)}
        )
```

**ç†ç”±**:
- åˆ†é›¢é©—è­‰å’ŒåŒ¯å…¥ç«¯é»,æä¾›æ›´å¥½çš„ä½¿ç”¨è€…é«”é©—
- ä½¿ç”¨ `UploadFile` ä¸²æµè™•ç†å¤§æª”æ¡ˆ
- è©³ç´°çš„éŒ¯èª¤è™•ç†å’Œæ—¥èªŒè¨˜éŒ„
- é©ç•¶çš„ HTTP ç‹€æ…‹ç¢¼

---

## 4. éŒ¯èª¤è™•ç†ç­–ç•¥

### 4.1 æ±ºç­–: åˆ†å±¤éŒ¯èª¤è™•ç†

```python
from enum import Enum
from typing import Optional, Dict, Any

class ErrorCategory(str, Enum):
    """éŒ¯èª¤é¡åˆ¥"""
    VALIDATION = "validation"
    SECURITY = "security"
    FILESYSTEM = "filesystem"
    NETWORK = "network"
    INTERNAL = "internal"


class DataOperationError(Exception):
    """è³‡æ–™æ“ä½œéŒ¯èª¤åŸºç¤é¡åˆ¥"""
    
    def __init__(self, message: str, category: ErrorCategory, 
                 details: Optional[Dict[str, Any]] = None):
        self.message = message
        self.category = category
        self.details = details or {}
        super().__init__(self.message)


class ValidationError(DataOperationError):
    """é©—è­‰éŒ¯èª¤"""
    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, ErrorCategory.VALIDATION, details)


class SecurityError(DataOperationError):
    """å®‰å…¨æ€§éŒ¯èª¤"""
    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, ErrorCategory.SECURITY, details)


class FileSystemError(DataOperationError):
    """æª”æ¡ˆç³»çµ±éŒ¯èª¤"""
    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, ErrorCategory.FILESYSTEM, details)


# éŒ¯èª¤è™•ç†ä¸­ä»‹å±¤
from fastapi import Request
from fastapi.responses import JSONResponse

@router.exception_handler(DataOperationError)
async def data_operation_error_handler(request: Request, exc: DataOperationError):
    """çµ±ä¸€éŒ¯èª¤è™•ç†"""
    
    status_code_map = {
        ErrorCategory.VALIDATION: 400,
        ErrorCategory.SECURITY: 403,
        ErrorCategory.FILESYSTEM: 500,
        ErrorCategory.INTERNAL: 500,
    }
    
    status_code = status_code_map.get(exc.category, 500)
    
    return JSONResponse(
        status_code=status_code,
        content={
            "error": exc.category.value,
            "message": exc.message,
            "details": exc.details
        }
    )
```

**ç†ç”±**:
- çµæ§‹åŒ–éŒ¯èª¤ä¾¿æ–¼å‰ç«¯è™•ç†
- å€åˆ†éŒ¯èª¤é¡å‹,æä¾›é©ç•¶çš„ HTTP ç‹€æ…‹ç¢¼
- è©³ç´°è³‡è¨Šæœ‰åŠ©æ–¼é™¤éŒ¯,ä½†ä¸æ´©éœ²æ•æ„Ÿè³‡è¨Š

---

## 5. æ¸¬è©¦ç­–ç•¥

### 5.1 å–®å…ƒæ¸¬è©¦ç¯„ä¾‹

```python
import pytest
from pathlib import Path
import tempfile
import zipfile

class TestZipValidator:
    """ZipValidator æ¸¬è©¦"""
    
    def test_valid_structure(self):
        """æ¸¬è©¦æœ‰æ•ˆçš„ç›®éŒ„çµæ§‹"""
        with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as f:
            zip_path = f.name
        
        try:
            # å»ºç«‹æ¸¬è©¦ ZIP
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                zipf.writestr('data/Day/20250101.md', '# Test')
                zipf.writestr('data/Week/20250105.md', '# Test')  # 2025/1/5 æ˜¯å‘¨æ—¥
                zipf.writestr('data/Month/202501.md', '# Test')
                zipf.writestr('data/Year/2025.md', '# Test')
            
            # é©—è­‰
            validator = ZipValidator()
            passed, report = validator.validate(zip_path)
            
            assert passed is True
            assert len(report['errors']) == 0
        
        finally:
            Path(zip_path).unlink()
    
    def test_invalid_week_date(self):
        """æ¸¬è©¦ç„¡æ•ˆçš„å‘¨è¨ˆç•«æ—¥æœŸ (éå‘¨æ—¥)"""
        with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as f:
            zip_path = f.name
        
        try:
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                zipf.writestr('data/Day/20250101.md', '# Test')
                zipf.writestr('data/Week/20250101.md', '# Test')  # 2025/1/1 æ˜¯å‘¨ä¸‰
                zipf.writestr('data/Month/202501.md', '# Test')
                zipf.writestr('data/Year/2025.md', '# Test')
            
            validator = ZipValidator()
            passed, report = validator.validate(zip_path)
            
            assert passed is False
            assert any('not Sunday' in err for err in report['errors'])
        
        finally:
            Path(zip_path).unlink()
    
    def test_zip_slip_protection(self):
        """æ¸¬è©¦ Zip Slip é˜²è­·"""
        with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as f:
            zip_path = f.name
        
        try:
            # å»ºç«‹æƒ¡æ„ ZIP
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                # å˜—è©¦è·¯å¾‘ç©¿è¶Š
                info = zipfile.ZipInfo('../../../etc/passwd')
                zipf.writestr(info, 'malicious content')
            
            # å˜—è©¦è§£å£“ç¸®
            with tempfile.TemporaryDirectory() as temp_dir:
                with pytest.raises(ValueError, match="Path Traversal"):
                    safe_extract_all(zip_path, temp_dir)
        
        finally:
            Path(zip_path).unlink()
    
    def test_file_size_limit(self):
        """æ¸¬è©¦æª”æ¡ˆå¤§å°é™åˆ¶"""
        with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as f:
            zip_path = f.name
        
        try:
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                # å»ºç«‹è¶…å¤§æª”æ¡ˆ (æ¨¡æ“¬)
                large_content = 'x' * (101 * 1024 * 1024)  # 101MB
                zipf.writestr('data/Day/20250101.md', large_content)
            
            validator = ZipValidator(max_total_size=100 * 1024 * 1024)
            passed, report = validator.validate(zip_path)
            
            assert passed is False
            assert any('too large' in err.lower() for err in report['errors'])
        
        finally:
            Path(zip_path).unlink()
```

---

## 6. æ•ˆèƒ½è€ƒé‡

### 6.1 æ•ˆèƒ½æŒ‡æ¨™

| æ“ä½œ | æª”æ¡ˆæ•¸ | ç¸½å¤§å° | é æœŸæ™‚é–“ | è¨˜æ†¶é«”ä½¿ç”¨ |
|------|--------|--------|----------|------------|
| åŒ¯å‡º | 1,000 | 5MB | < 3s | ~20MB |
| åŒ¯å‡º | 10,000 | 50MB | < 30s | ~20MB |
| é©—è­‰ | 1,000 | 5MB | < 2s | ~10MB |
| åŒ¯å…¥ | 1,000 | 5MB | < 5s | ~30MB |

### 6.2 å„ªåŒ–å»ºè­°

1. **å¤§æª”æ¡ˆè™•ç†**: ä½¿ç”¨ `compresslevel=6` å¹³è¡¡é€Ÿåº¦èˆ‡å£“ç¸®ç‡
2. **ä¸¦è¡Œè™•ç†**: å°æ–¼æ¥µå¤§è³‡æ–™é›†,å¯è€ƒæ…®ä½¿ç”¨ `multiprocessing` ä¸¦è¡Œå£“ç¸®
3. **å¿«å–**: å°åŒ¯å‡ºæª”æ¡ˆå¯¦ä½œå¿«å–æ©Ÿåˆ¶(å¦‚è³‡æ–™æœªè®Šæ›´å‰‡é‡ç”¨)
4. **é€²åº¦å›é¥‹**: å°é•·æ™‚é–“æ“ä½œæä¾› WebSocket é€²åº¦æ›´æ–°

---

## 7. å®‰å…¨æ€§æª¢æŸ¥æ¸…å–®

- âœ… **Zip Slip é˜²è­·**: ä½¿ç”¨ `Path.resolve()` é©—è­‰è·¯å¾‘
- âœ… **æª”æ¡ˆå¤§å°é™åˆ¶**: é˜²æ­¢ DoS æ”»æ“Š
- âœ… **æª”æ¡ˆæ•¸é‡é™åˆ¶**: é˜²æ­¢è³‡æºè€—ç›¡
- âœ… **æª”åé©—è­‰**: é˜²æ­¢ç‰¹æ®Šå­—å…ƒå’Œè·¯å¾‘ç©¿è¶Š
- âœ… **æ—¥æœŸé©—è­‰**: é˜²æ­¢ç„¡æ•ˆæ—¥æœŸ
- âœ… **æª”æ¡ˆé¡å‹é™åˆ¶**: åªå…è¨± .md æª”æ¡ˆ
- âœ… **åŸå­æ€§æ“ä½œ**: å¤±æ•—æ™‚å®Œæ•´å›æ»¾
- âœ… **è©³ç´°æ—¥èªŒ**: è¨˜éŒ„æ‰€æœ‰æ“ä½œä¾›ç¨½æ ¸

---

## 8. æ¨è–¦çš„å¯¦ä½œé †åº

1. **éšæ®µ 1**: å¯¦ä½œ `ZipValidator` å’Œæ¸¬è©¦ (1-2 å¤©)
2. **éšæ®µ 2**: å¯¦ä½œåŒ¯å‡ºåŠŸèƒ½å’Œ API ç«¯é» (1 å¤©)
3. **éšæ®µ 3**: å¯¦ä½œå®‰å…¨è§£å£“ç¸®å‡½å¼ (1 å¤©)
4. **éšæ®µ 4**: å¯¦ä½œ `DataImporter` å’ŒåŸå­æ€§æ“ä½œ (2 å¤©)
5. **éšæ®µ 5**: æ•´åˆæ¸¬è©¦å’Œå®‰å…¨æ€§æ¸¬è©¦ (1-2 å¤©)
6. **éšæ®µ 6**: å‰ç«¯æ•´åˆå’Œ UI é–‹ç™¼ (2-3 å¤©)

**ç¸½è¨ˆ**: ç´„ 8-11 å¤©

---

## 9. æ›¿ä»£æ–¹æ¡ˆæ¯”è¼ƒ

| æ–¹æ¡ˆ | å„ªé» | ç¼ºé» | æ¨è–¦åº¦ |
|------|------|------|--------|
| **zipfile æ¨™æº–åº«** | ç„¡ä¾è³´ã€ç©©å®šã€æ–‡ä»¶å®Œæ•´ | API è¼ƒä½éš | â­â­â­â­â­ |
| **tarfile** | Unix åŸç”Ÿæ”¯æ´ | Windows ç›¸å®¹æ€§å·® | â­â­ |
| **7-Zip (py7zr)** | é«˜å£“ç¸®ç‡ | éœ€é¡å¤–ä¾è³´ | â­â­â­ |
| **è‡ªå®šç¾©æ ¼å¼** | å®Œå…¨æ§åˆ¶ | é–‹ç™¼æˆæœ¬é«˜ | â­ |

**çµè«–**: `zipfile` æ¨™æº–åº«æ˜¯æœ€ä½³é¸æ“‡,ç„¡éœ€é¡å¤–ä¾è³´ä¸”è·¨å¹³å°æ”¯æ´å®Œæ•´ã€‚

---

## 10. åƒè€ƒè³‡æº

- [Python zipfile å®˜æ–¹æ–‡ä»¶](https://docs.python.org/3/library/zipfile.html)
- [OWASP Zip Slip æ¼æ´èªªæ˜](https://github.com/snyk/zip-slip-vulnerability)
- [FastAPI æª”æ¡ˆä¸Šå‚³æŒ‡å—](https://fastapi.tiangolo.com/tutorial/request-files/)
- [Python tempfile æœ€ä½³å¯¦è¸](https://docs.python.org/3/library/tempfile.html)

---

## é™„éŒ„ A: å®Œæ•´ä½¿ç”¨ç¯„ä¾‹

```python
# backend/data_export_service.py
from datetime import datetime
from pathlib import Path
import zipfile
import os

class DataExportService:
    """å®Œæ•´çš„è³‡æ–™åŒ¯å‡ºæœå‹™"""
    
    def __init__(self, data_dir: str = "backend/data"):
        self.data_dir = Path(data_dir)
    
    def export(self, output_path: str = None) -> dict:
        """åŸ·è¡ŒåŒ¯å‡º"""
        if not output_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"export_data_{timestamp}.zip"
        
        stats = {'files': 0, 'size': 0, 'compressed': 0}
        
        with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:
            for root, dirs, files in os.walk(self.data_dir):
                # éæ¿¾
                files = [f for f in files if f.endswith('.md') and not f.startswith('.')]
                dirs[:] = [d for d in dirs if not d.startswith('.')]
                
                for file in files:
                    file_path = Path(root) / file
                    arcname = file_path.relative_to(self.data_dir.parent)
                    zipf.write(file_path, arcname=arcname)
                    
                    stats['files'] += 1
                    stats['size'] += file_path.stat().st_size
        
        stats['compressed'] = Path(output_path).stat().st_size
        stats['ratio'] = f"{(1 - stats['compressed'] / stats['size']) * 100:.1f}%"
        
        return stats


# ä½¿ç”¨
if __name__ == "__main__":
    service = DataExportService()
    result = service.export()
    print(f"Exported {result['files']} files")
    print(f"Original: {result['size']} bytes")
    print(f"Compressed: {result['compressed']} bytes")
    print(f"Compression ratio: {result['ratio']}")
```

---

**ç ”ç©¶å®Œæˆæ—¥æœŸ**: 2025-10-25  
**å»ºè­°å¯©æŸ¥è€…**: Backend Lead, Security Team  
**ä¸‹ä¸€æ­¥**: é–‹å§‹å¯¦ä½œ `ZipValidator` é¡åˆ¥
